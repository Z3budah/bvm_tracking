{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1554dfc1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f67fa75",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "D = 30\n",
    "K = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c54cc91",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_dir = \"../action/new_keypoint\"\n",
    "\n",
    "action_pattern = \"normal general movement\"\n",
    "# list of keypoints file paths\n",
    "keypoint_files = sorted(\n",
    "    [\n",
    "        os.path.join(keypoint_dir, fname)\n",
    "        for fname in os.listdir(keypoint_dir)\n",
    "        #if fname.endswith(\".npy\")\n",
    "        if action_pattern in fname\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b6ed6c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db497029",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.load(keypoint_files[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b86be3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fps = 25.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e11c3",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sequence class to load and vectorize batches of data\n",
    "class Keypoints(keras.utils.Sequence):# iterate images\n",
    "    def __init__(self, frame_batch, keypoint_files):\n",
    "        self.frame_batch = frame_batch\n",
    "        self.files = keypoint_files\n",
    "        self.keypoints = []\n",
    "        for f_path in self.files:\n",
    "            raw_kp = np.load(f_path) \n",
    "            # number of batches this keypoint file will be split to \n",
    "            n_frame_batches = len(raw_kp) // frame_batch\n",
    "            for i in range(n_frame_batches):\n",
    "                # divided the long keypoints sequence to batch_size frames\n",
    "                kp = raw_kp[i*frame_batch:(i+1)*frame_batch,0:14,0:2]\n",
    "                self.keypoints.append(kp) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "    \n",
    "    def encode(self, batch):\n",
    "        frame_batch = self.frame_batch\n",
    "        features = 9\n",
    "        joints = 14\n",
    "        # motion encoder\n",
    "        A = np.zeros((frame_batch, joints, features))\n",
    "        \n",
    "        for j in range(0,joints): # for each joint\n",
    "            for i in range(1,frame_batch):\n",
    "                # displacement \n",
    "      \n",
    "                A[i][j][0],  A[i][j][1]= batch[i][j] - batch[i-1][j]  \n",
    "                A[i][j][2] = math.sqrt(A[i][j][0]**2 + A[i][j][1]**2)\n",
    "\n",
    "                # speed\n",
    "                A[i][j][3],  A[i][j][4] = (batch[i][j] - batc\n",
    "                                           h[i-1][j])*fps \n",
    "                A[i][j][5] = A[i][j][2] * fps\n",
    "\n",
    "                # distance from joint j to spine_base\n",
    "                spine_base = (batch[i][8]+batch[i][11])/2\n",
    "                A[i][j][6], A[i][j][7] = batch[i][j] - spine_base\n",
    "                A[i][j][8] = math.sqrt(A[i][j][6]**2 + A[i][j][7]**2)\n",
    "\n",
    "        return A\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # encoded = []\n",
    "        # for kp in self.keypoints[index*frame_batch : (index+1)*frame_batch]:\n",
    "        #     encoded.append(self.encode(kp)) \n",
    "        # encoded = np.array(encoded)\n",
    "        # print(f\"Generated batch data shape: {encoded.shape}\")\n",
    "        return self.encode(self.keypoints[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff676ab",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "frame_batch = 256\n",
    "# Instantiate data Sequences for each split\n",
    "data_generator = Keypoints(frame_batch, keypoint_files[0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df248b9",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_generator[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48673418",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DotLayer(tf.keras.layers.Layer):\n",
    " \n",
    "    def __init__(self, units=8):\n",
    "        super(DotLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # initialize the prototype\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True,\n",
    "                               name='dot_layer')\n",
    "        print(\"initialize the prototype\")\n",
    " \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9feaf25c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    # D: the dimension of the embedding features \n",
    "    # K: the number of cluster \n",
    "    # KL_weight: balance weight of the similarity term and the temporal order-preserving term\n",
    "    # SK_inter: the number of Sinkhorn-Knopp iteration\n",
    "    # alpha: weight of temporal coherence loss\n",
    "    def __init__(self, frame_batch, D=30, K=8, KL_weight=0.1, SK_inter=5, alpha=1.0, T=10.0):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.klw = KL_weight\n",
    "        self.nit = SK_inter\n",
    "\n",
    "        self.frame_batch = frame_batch\n",
    "        self.alpha = alpha\n",
    "        # self.model = self.build_model()\n",
    "\n",
    "        # 2-layer MLP   \n",
    "        self.dense1 = tf.keras.layers.Dense(units=2*D, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=D, activation='sigmoid')\n",
    "        self.dot1 = DotLayer()\n",
    "        self.softmax1 = tf.keras.layers.Softmax()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "      features = 9\n",
    "      joints = 14\n",
    "      D = self.D\n",
    "      T = self.T\n",
    "      frame_batch = self.frame_batch \n",
    "      x = inputs\n",
    "      x = tf.reshape(x, shape=(-1, joints*features))\n",
    "\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "\n",
    "      self.Z = x\n",
    "\n",
    "      x = self.dot1(x)\n",
    "      outputs = self.softmax1(x/T)\n",
    "      \n",
    "      return outputs\n",
    "    \n",
    "    def compile(self):\n",
    "        super(MyModel, self).compile()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-4)\n",
    "        \n",
    "    # build the encoder network\n",
    "    # def build_model(self):\n",
    "    #     features = 9\n",
    "    #     joints = 14\n",
    "    #     D = self.D\n",
    "    #     batch_size = self.batch_size\n",
    "    #     frame_batch = self.frame_batch \n",
    "    #     # inputs = keras.Input(shape=(joints, features))\n",
    "    #     inputs = keras.Input(shape=(frame_batch, joints, features))\n",
    "    #     x = inputs\n",
    "    #     # x = tf.keras.layers.Flatten()(x)\n",
    "    #     x = tf.reshape(x, shape=(-1, frame_batch, joints*features))\n",
    "        \n",
    "    #     # 2-layer MLP    \n",
    "    #     x = tf.keras.layers.Dense(units=2*D, activation='sigmoid')(x)\n",
    "    #     x = tf.keras.layers.Dense(units=D, activation='sigmoid')(x)\n",
    "        \n",
    "    #     # save the embedding features\n",
    "    #     self.Z = x\n",
    "\n",
    "    #     linear_layer = DotLayer()\n",
    "    #     x = linear_layer(x)\n",
    "    #     # P_ij \n",
    "    #     outputs = tf.keras.layers.Softmax()(x)\n",
    "        \n",
    "    #     return keras.Model(inputs, outputs)\n",
    "        \n",
    "    \n",
    "    def get_prior(self, x):\n",
    "        frame_batch = self.frame_batch\n",
    "        var = tf.math.reduce_variance(x)\n",
    "        std = tf.math.reduce_std(x)\n",
    "\n",
    "        T = []\n",
    "        for i in range(frame_batch):\n",
    "          T_i = []\n",
    "          for j in range(K):\n",
    "            d_ij = abs(i/frame_batch-j/K)/tf.math.sqrt(1/(frame_batch**2)+1/(K**2))\n",
    "            # Gaussian distribution \n",
    "            T_i.append(tf.math.exp(-d_ij**2/(2*var))/std*math.sqrt(2*math.pi))\n",
    "          T.append(T_i)\n",
    "        T = tf.stack(T)\n",
    "        return T\n",
    "        \n",
    "    def temporal_ot(self, x):\n",
    "        Z = self.Z\n",
    "        # C: learnable prototypes of the K clusters\n",
    "        C = self.trainable_variables[-1]\n",
    "        tf.print(tf.math.reduce_max(C))\n",
    "        T = self.get_prior(x)\n",
    "\n",
    "        \n",
    "        frame_batch = self.frame_batch\n",
    "        k_cluster = self.K\n",
    "        # balance weight of the similarity term and the temporal order-preserving term\n",
    "        klw = self.klw\n",
    "        \n",
    "        # Sinkhorn-Knopp Algorithm\n",
    "        v = np.ones((k_cluster,1))\n",
    "        u = np.ones((frame_batch,1))\n",
    "\n",
    "        a = u / frame_batch\n",
    "        b = v / k_cluster \n",
    "        K = tf.math.exp((tf.matmul(Z,C) + klw*tf.math.log(T))/klw) \n",
    "        # nit the number of Sinkhorn-Knopp iteration\n",
    "        for i in range(1,self.nit):\n",
    "        #v = b / np.dot(K.T, u), u = a / np.dot(K, v)\n",
    "          v = b / tf.matmul(tf.transpose(K), u)\n",
    "          u = a / tf.matmul(K, v)\n",
    "\n",
    "        v = tf.squeeze(v)\n",
    "        u = tf.squeeze(u)\n",
    "        \n",
    "        Q_TOT=tf.matmul(tf.linalg.diag(u),tf.matmul(K, tf.linalg.diag(v)))\n",
    "        tf.print(tf.math.reduce_max(Q_TOT))\n",
    "        return tf.stack(Q_TOT)\n",
    "        \n",
    "    def loss_func(self, P, Q):\n",
    "\n",
    "        frame_batch = self.frame_batch\n",
    "        # Cross-Entropy Loss\n",
    "        l_ce = -tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P)))/frame_batch\n",
    "        tf.print(tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P))))\n",
    "        # Temporal Coherence Loss - N pair loss\n",
    "        Z = self.Z\n",
    "        \n",
    "        N = 8\n",
    "        l = int(frame_batch/N)\n",
    "\n",
    "        Z_i = []\n",
    "        Z_positive = []\n",
    "        window_size = 4\n",
    "        # sample z_i\n",
    "        for i in range(N):\n",
    "          index = i*l + np.random.randint(0,l-1,1)\n",
    "          z_i = tf.gather(Z, index, axis=0)\n",
    "          Z_i.append(z_i)\n",
    "          \n",
    "          # calculate window range\n",
    "          min_index = max(0, index - window_size)\n",
    "          max_index = min(frame_batch - 1, index + window_size)\n",
    "          # sample z_postive inside the window\n",
    "          idx_pos = np.random.randint(min_index, max_index,1)\n",
    "          z_ip = tf.squeeze(tf.gather(Z, idx_pos, axis=0))\n",
    "          Z_positive.append(z_ip)\n",
    "\n",
    "        Z_i = tf.stack(Z_i)\n",
    "        Z_positive = tf.stack(Z_positive)\n",
    "\n",
    "\n",
    "        l_tc = 0\n",
    "        for i in range(N):  \n",
    "          denominator = tf.reduce_sum(tf.exp(tf.matmul(Z_i[i],tf.transpose(Z_positive))),axis=1, keepdims=True)\n",
    "          l_tc += tf.squeeze(tf.math.log(tf.exp(tf.matmul(Z_i[i],tf.reshape(Z_positive[i],shape=(self.D,1)))/denominator)))\n",
    "        l_tc = - l_tc/N\n",
    "        tf.print(\"LCE:\", l_ce,\"LTC:\",l_tc)\n",
    "        return l_ce + self.alpha*l_tc\n",
    "        \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            P = self(x, training=True)\n",
    "            Q = self.temporal_ot(x)\n",
    "            loss = self.loss_func(P,Q)\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # update weights using the optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    def get_config(self):\n",
    "\n",
    "        return {\"frame_batch\": self.frame_batch,\"D\": self.D, \"K\": self.K,\"KL_weight\": self.klw,\"SK_inter\": self.nit,\"alpha\": self.alpha,\"T\": self.T}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27f3e944",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    # D: the dimension of the embedding features \n",
    "    # K: the number of cluster \n",
    "    # KL_weight: balance weight of the similarity term and the temporal order-preserving term\n",
    "    # SK_inter: the number of Sinkhorn-Knopp iteration\n",
    "    # alpha: weight of temporal coherence loss\n",
    "    def __init__(self, frame_batch, D=30, K=8, KL_weight=0.1, SK_inter=5, alpha=1.0, T=10.0):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.klw = KL_weight\n",
    "        self.nit = SK_inter\n",
    "\n",
    "        self.frame_batch = frame_batch\n",
    "        self.alpha = alpha\n",
    "        # self.model = self.build_model()\n",
    "\n",
    "        # 2-layer MLP   \n",
    "        self.dense1 = tf.keras.layers.Dense(units=2*D, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=D, activation='sigmoid')\n",
    "        self.dot1 = DotLayer()\n",
    "        self.softmax1 = tf.keras.layers.Softmax()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "      features = 9\n",
    "      joints = 14\n",
    "      D = self.D\n",
    "      T = self.T\n",
    "      frame_batch = self.frame_batch \n",
    "      x = inputs\n",
    "      x = tf.reshape(x, shape=(-1, joints*features))\n",
    "\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "\n",
    "      self.Z = x\n",
    "\n",
    "      x = self.dot1(x)\n",
    "      outputs = self.softmax1(x/T)\n",
    "      \n",
    "      return outputs\n",
    "    \n",
    "    def compile(self):\n",
    "        super(MyModel, self).compile()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-4)\n",
    "        \n",
    "    # build the encoder network\n",
    "    # def build_model(self):\n",
    "    #     features = 9\n",
    "    #     joints = 14\n",
    "    #     D = self.D\n",
    "    #     batch_size = self.batch_size\n",
    "    #     frame_batch = self.frame_batch \n",
    "    #     # inputs = keras.Input(shape=(joints, features))\n",
    "    #     inputs = keras.Input(shape=(frame_batch, joints, features))\n",
    "    #     x = inputs\n",
    "    #     # x = tf.keras.layers.Flatten()(x)\n",
    "    #     x = tf.reshape(x, shape=(-1, frame_batch, joints*features))\n",
    "        \n",
    "    #     # 2-layer MLP    \n",
    "    #     x = tf.keras.layers.Dense(units=2*D, activation='sigmoid')(x)\n",
    "    #     x = tf.keras.layers.Dense(units=D, activation='sigmoid')(x)\n",
    "        \n",
    "    #     # save the embedding features\n",
    "    #     self.Z = x\n",
    "\n",
    "    #     linear_layer = DotLayer()\n",
    "    #     x = linear_layer(x)\n",
    "    #     # P_ij \n",
    "    #     outputs = tf.keras.layers.Softmax()(x)\n",
    "        \n",
    "    #     return keras.Model(inputs, outputs)\n",
    "        \n",
    "    \n",
    "    def get_prior(self, x):\n",
    "        frame_batch = self.frame_batch\n",
    "        var = tf.math.reduce_variance(x)\n",
    "        std = tf.math.reduce_std(x)\n",
    "\n",
    "        T = []\n",
    "        for i in range(frame_batch):\n",
    "          T_i = []\n",
    "          for j in range(K):\n",
    "            d_ij = abs(i/frame_batch-j/K)/tf.math.sqrt(1/(frame_batch**2)+1/(K**2))\n",
    "            # Gaussian distribution \n",
    "            T_i.append(tf.math.exp(-d_ij**2/(2*var))/std*math.sqrt(2*math.pi))\n",
    "          T.append(T_i)\n",
    "        T = tf.stack(T)\n",
    "        return T\n",
    "        \n",
    "    def temporal_ot(self, x):\n",
    "        Z = self.Z\n",
    "        # C: learnable prototypes of the K clusters\n",
    "        C = self.trainable_variables[-1]\n",
    "        tf.print(tf.math.reduce_max(C))\n",
    "        T = self.get_prior(x)\n",
    "\n",
    "        \n",
    "        frame_batch = self.frame_batch\n",
    "        k_cluster = self.K\n",
    "        # balance weight of the similarity term and the temporal order-preserving term\n",
    "        klw = self.klw\n",
    "        \n",
    "        # Sinkhorn-Knopp Algorithm\n",
    "        v = np.ones((k_cluster,1))\n",
    "        u = np.ones((frame_batch,1))\n",
    "\n",
    "        a = u / frame_batch\n",
    "        b = v / k_cluster \n",
    "        K = tf.math.exp((tf.matmul(Z,C) + klw*tf.math.log(T))/klw) \n",
    "        # nit the number of Sinkhorn-Knopp iteration\n",
    "        for i in range(1,self.nit):\n",
    "        #v = b / np.dot(K.T, u), u = a / np.dot(K, v)\n",
    "          v = b / tf.matmul(tf.transpose(K), u)\n",
    "          u = a / tf.matmul(K, v)\n",
    "\n",
    "        v = tf.squeeze(v)\n",
    "        u = tf.squeeze(u)\n",
    "        \n",
    "        Q_TOT=tf.matmul(tf.linalg.diag(u),tf.matmul(K, tf.linalg.diag(v)))\n",
    "        tf.print(tf.math.reduce_max(Q_TOT))\n",
    "        return tf.stack(Q_TOT)\n",
    "        \n",
    "    def loss_func(self, P, Q):\n",
    "\n",
    "        frame_batch = self.frame_batch\n",
    "        # Cross-Entropy Loss\n",
    "        l_ce = -tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P)))/frame_batch\n",
    "        tf.print(tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P))))\n",
    "        # Temporal Coherence Loss - N pair loss\n",
    "        Z = self.Z\n",
    "        \n",
    "        N = 8\n",
    "        l = int(frame_batch/N)\n",
    "\n",
    "        Z_i = []\n",
    "        Z_positive = []\n",
    "        window_size = 4\n",
    "        # sample z_i\n",
    "        for i in range(N):\n",
    "          index = i*l + np.random.randint(0,l-1,1)\n",
    "          z_i = tf.gather(Z, index, axis=0)\n",
    "          Z_i.append(z_i)\n",
    "          \n",
    "          # calculate window range\n",
    "          min_index = max(0, index - window_size)\n",
    "          max_index = min(frame_batch - 1, index + window_size)\n",
    "          # sample z_postive inside the window\n",
    "          idx_pos = np.random.randint(min_index, max_index,1)\n",
    "          z_ip = tf.squeeze(tf.gather(Z, idx_pos, axis=0))\n",
    "          Z_positive.append(z_ip)\n",
    "\n",
    "        Z_i = tf.stack(Z_i)\n",
    "        Z_positive = tf.stack(Z_positive)\n",
    "\n",
    "\n",
    "        l_tc = 0\n",
    "        for i in range(N):  \n",
    "          denominator = tf.reduce_sum(tf.exp(tf.matmul(Z_i[i],tf.transpose(Z_positive))),axis=1, keepdims=True)\n",
    "          l_tc += tf.squeeze(tf.math.log(tf.exp(tf.matmul(Z_i[i],tf.reshape(Z_positive[i],shape=(self.D,1)))/denominator)))\n",
    "        l_tc = - l_tc/N\n",
    "        tf.print(\"LCE:\", l_ce,\"LTC:\",l_tc)\n",
    "        return l_ce + self.alpha*l_tc\n",
    "        \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            P = self(x, training=True)\n",
    "            Q = self.temporal_ot(x)\n",
    "            loss = self.loss_func(P,Q)\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # update weights using the optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    def get_config(self):\n",
    "\n",
    "        return {\"frame_batch\": self.frame_batch,\"D\": self.D, \"K\": self.K,\"KL_weight\": self.klw,\"SK_inter\": self.nit,\"alpha\": self.alpha,\"T\": self.T}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee8d1e0-a00b-482c-a77c-29f4798a8400",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize the prototype\n",
      "Model: \"my_model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              multiple                  7620      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  1830      \n",
      "_________________________________________________________________\n",
      "dot_layer_1 (DotLayer)       multiple                  240       \n",
      "_________________________________________________________________\n",
      "softmax_1 (Softmax)          multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9,690\n",
      "Trainable params: 9,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(frame_batch)\n",
    "model.compile()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"motion_tracking.h5\", save_best_only=True)]\n",
    "model.build(input_shape=(frame_batch, 14, 9))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "-B_1H5tO683m",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B_1H5tO683m",
    "outputId": "f55c67c5-44e6-437b-f0d4-f080a91d523d",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "0.169735909\n",
      "0.000871030614\n",
      "-2.07936835\n",
      "LCE: 0.00812253263 LTC: -0.0447713658\n",
      "1/7 [===>..........................] - ETA: 0s - loss: -0.04400.169925\n",
      "0.000875758\n",
      "-2.0792017\n",
      "LCE: 0.00812188163 LTC: -0.0443792976\n",
      "2/7 [=======>......................] - ETA: 0s - loss: -0.04380.170111343\n",
      "0.00108204782\n",
      "-2.07915974\n",
      "LCE: 0.00812171772 LTC: -0.0454110689\n",
      "3/7 [===========>..................] - ETA: 0s - loss: -0.04400.170296207\n",
      "0.000945484266\n",
      "-2.0791266\n",
      "LCE: 0.00812158827 LTC: -0.0450742841\n",
      "4/7 [================>.............] - ETA: 0s - loss: -0.04410.170476437\n",
      "0.000785999466\n",
      "-2.07929873\n",
      "LCE: 0.00812226068 LTC: -0.0444250777\n",
      "5/7 [====================>.........] - ETA: 0s - loss: -0.04400.170650199\n",
      "0.000896688085\n",
      "-2.07921171\n",
      "LCE: 0.00812192075 LTC: -0.0456749722\n",
      "6/7 [========================>.....] - ETA: 0s - loss: -0.04410.170814648\n",
      "0.000889795832\n",
      "-2.07916975\n",
      "LCE: 0.00812175684 LTC: -0.0466056317\n",
      "7/7 [==============================] - 1s 106ms/step - loss: -0.0446\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 2/5\n",
      "0.170977697\n",
      "0.000905837398\n",
      "-2.07935667\n",
      "LCE: 0.00812248699 LTC: -0.0459426343\n",
      "1/7 [===>..........................] - ETA: 0s - loss: -0.04510.171131596\n",
      "0.00088745635\n",
      "-2.07923865\n",
      "LCE: 0.00812202599 LTC: -0.0458324291\n",
      "2/7 [=======>......................] - ETA: 0s - loss: -0.04510.171280444\n",
      "0.00100818463\n",
      "-2.07917356\n",
      "LCE: 0.00812177174 LTC: -0.0450865626\n",
      "3/7 [===========>..................] - ETA: 0s - loss: -0.04480.171429679\n",
      "0.000813782681\n",
      "-2.07930017\n",
      "LCE: 0.00812226627 LTC: -0.0462120175\n",
      "4/7 [================>.............] - ETA: 0s - loss: -0.04500.171574578\n",
      "0.000884057488\n",
      "-2.07916784\n",
      "LCE: 0.00812174939 LTC: -0.0467135161\n",
      "5/7 [====================>.........] - ETA: 0s - loss: -0.04510.171721146\n",
      "0.000912793446\n",
      "-2.0792\n",
      "LCE: 0.00812187511 LTC: -0.0454398803\n",
      "6/7 [========================>.....] - ETA: 0s - loss: -0.04510.17187275\n",
      "0.00103930943\n",
      "-2.07915211\n",
      "LCE: 0.00812168792 LTC: -0.045836471\n",
      "7/7 [==============================] - 1s 107ms/step - loss: -0.0451\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 3/5\n",
      "0.172027975\n",
      "0.00104151014\n",
      "-2.0790534\n",
      "LCE: 0.00812130235 LTC: -0.0461339951\n",
      "1/7 [===>..........................] - ETA: 0s - loss: -0.04530.172187477\n",
      "0.000914265867\n",
      "-2.07915926\n",
      "LCE: 0.00812171586 LTC: -0.0457290262\n",
      "2/7 [=======>......................] - ETA: 0s - loss: -0.04510.17234838\n",
      "0.000965055544\n",
      "-2.07916784\n",
      "LCE: 0.00812174939 LTC: -0.0469426699\n",
      "3/7 [===========>..................] - ETA: 0s - loss: -0.04550.17251043\n",
      "0.00102811027\n",
      "-2.07909727\n",
      "LCE: 0.00812147371 LTC: -0.0451312512\n",
      "4/7 [================>.............] - ETA: 0s - loss: -0.04520.172670186\n",
      "0.000885063782\n",
      "-2.07925534\n",
      "LCE: 0.00812209118 LTC: -0.0461037755\n",
      "5/7 [====================>.........] - ETA: 0s - loss: -0.04520.172823012\n",
      "0.00081684906\n",
      "-2.07928944\n",
      "LCE: 0.00812222436 LTC: -0.0467024818\n",
      "6/7 [========================>.....] - ETA: 0s - loss: -0.04530.17297256\n",
      "0.000830214471\n",
      "-2.0793004\n",
      "LCE: 0.0081222672 LTC: -0.0456166826\n",
      "7/7 [==============================] - 1s 106ms/step - loss: -0.0452\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 4/5\n",
      "0.17311208\n",
      "0.000821665861\n",
      "-2.07934332\n",
      "LCE: 0.00812243484 LTC: -0.0456316285\n",
      "1/7 [===>..........................] - ETA: 0s - loss: -0.04480.173243687\n",
      "0.0010664016\n",
      "-2.07912064\n",
      "LCE: 0.00812156498 LTC: -0.0457767025\n",
      "2/7 [=======>......................] - ETA: 0s - loss: -0.04490.173376456\n",
      "0.000888486393\n",
      "-2.07914734\n",
      "LCE: 0.00812166929 LTC: -0.0462945327\n",
      "3/7 [===========>..................] - ETA: 0s - loss: -0.04510.173504695\n",
      "0.000827327371\n",
      "-2.07924104\n",
      "LCE: 0.0081220353 LTC: -0.0469224975\n",
      "4/7 [================>.............] - ETA: 0s - loss: -0.04530.173631266\n",
      "0.000931599177\n",
      "-2.07916713\n",
      "LCE: 0.00812174659 LTC: -0.0474675111\n",
      "5/7 [====================>.........] - ETA: 0s - loss: -0.04560.173760116\n",
      "0.000933046918\n",
      "-2.07909894\n",
      "LCE: 0.00812148 LTC: -0.0457845069\n",
      "6/7 [========================>.....] - ETA: 0s - loss: -0.04550.173893929\n",
      "0.00103997625\n",
      "-2.0791564\n",
      "LCE: 0.00812170468 LTC: -0.0466087349\n",
      "7/7 [==============================] - 1s 104ms/step - loss: -0.0456\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "Epoch 5/5\n",
      "0.174034238\n",
      "0.0010285303\n",
      "-2.07915235\n",
      "LCE: 0.00812168885 LTC: -0.0464007072\n",
      "1/7 [===>..........................] - ETA: 0s - loss: -0.04560.174173817\n",
      "0.000940816943\n",
      "-2.07912374\n",
      "LCE: 0.00812157709 LTC: -0.0459214747\n",
      "2/7 [=======>......................] - ETA: 0s - loss: -0.04530.174318418\n",
      "0.000819996\n",
      "-2.07927704\n",
      "LCE: 0.00812217593 LTC: -0.0470357761\n",
      "3/7 [===========>..................] - ETA: 0s - loss: -0.04560.174459502\n",
      "0.000806507654\n",
      "-2.07923126\n",
      "LCE: 0.00812199712 LTC: -0.0464215577\n",
      "4/7 [================>.............] - ETA: 0s - loss: -0.04560.174595386\n",
      "0.000856442377\n",
      "-2.07912946\n",
      "LCE: 0.00812159944 LTC: -0.0477714166\n",
      "5/7 [====================>.........] - ETA: 0s - loss: -0.04590.174733594\n",
      "0.00104092341\n",
      "-2.0791316\n",
      "LCE: 0.00812160783 LTC: -0.046862334\n",
      "6/7 [========================>.....] - ETA: 0s - loss: -0.04590.174877629\n",
      "0.000800951384\n",
      "-2.07936287\n",
      "LCE: 0.00812251121 LTC: -0.0458195135\n",
      "7/7 [==============================] - 1s 99ms/step - loss: -0.0457\n",
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(data_generator, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d2TRuvvlTrH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "4d2TRuvvlTrH",
    "outputId": "3a14f8ef-cbd8-4ebc-b03e-af8be668c4af",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1,6)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "eGJ6lBh4gq5z",
   "metadata": {
    "id": "eGJ6lBh4gq5z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save('/content/gdrive/MyDrive/Colab Notebooks/logs/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aRXgpjOFVJsf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRXgpjOFVJsf",
    "outputId": "34a4f70f-1c94-4a67-88a0-bbe7ef2d8320",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = model.predict(data_generator[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "MSSYVGgHd3yJ",
   "metadata": {
    "id": "MSSYVGgHd3yJ",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "P = np.argmax(P, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "RPn4xsB2fgab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPn4xsB2fgab",
    "outputId": "46ab21b7-9129-43f4-a1ac-9696b753a513",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0390625"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "sTAngD-9fiTX",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTAngD-9fiTX",
    "outputId": "7dffad7b-64c3-4a3c-8ae1-8c42e23c12d7",
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 7, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MNPlTgJN52sR",
   "metadata": {
    "id": "MNPlTgJN52sR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}