{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "# mount google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QGyrZtrDsjVm",
    "outputId": "7ed63cb6-ee9f-4d55-f0b5-b5a4a6244c39",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "QGyrZtrDsjVm",
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a99fc38-a27d-4097-9768-7a5498f78cc8",
   "metadata": {
    "tags": [],
    "id": "2a99fc38-a27d-4097-9768-7a5498f78cc8",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import logging\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c48e0b74-616d-41d2-99a6-1c355205616d",
   "metadata": {
    "tags": [],
    "id": "c48e0b74-616d-41d2-99a6-1c355205616d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "D = 30\n",
    "K = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9acbc0d8-28c5-4cc5-b5f9-1ef8abd9e088",
   "metadata": {
    "tags": [],
    "id": "9acbc0d8-28c5-4cc5-b5f9-1ef8abd9e088",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "keypoint_dir = \"/content/gdrive/MyDrive/keypoint\"\n",
    "# list of keypoints file paths\n",
    "keypoint_files = sorted(\n",
    "    [\n",
    "        os.path.join(keypoint_dir, fname)\n",
    "        for fname in os.listdir(keypoint_dir)\n",
    "        if fname.endswith(\".npy\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1db84101-2bb5-4327-87d8-6edc8e082410",
   "metadata": {
    "tags": [],
    "id": "1db84101-2bb5-4327-87d8-6edc8e082410",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "fps = 25.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22b41d92-0601-462e-930f-e30371fdb968",
   "metadata": {
    "tags": [],
    "id": "22b41d92-0601-462e-930f-e30371fdb968",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sequence class to load and vectorize batches of data\n",
    "class Keypoints(keras.utils.Sequence):# iterate images\n",
    "    def __init__(self, frame_batch, keypoint_files):\n",
    "        self.frame_batch = frame_batch\n",
    "        self.files = keypoint_files\n",
    "        self.keypoints = []\n",
    "        for f_path in self.files:\n",
    "            raw_kp = np.load(f_path) \n",
    "            # number of batches this keypoint file will be split to \n",
    "            n_frame_batches = len(raw_kp) // frame_batch\n",
    "            for i in range(n_frame_batches):\n",
    "                # divided the long keypoints sequence to batch_size frames\n",
    "                kp = raw_kp[i*frame_batch:(i+1)*frame_batch,0:14,0:2]\n",
    "                self.keypoints.append(kp) \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "    \n",
    "    def encode(self, batch):\n",
    "        frame_batch = self.frame_batch\n",
    "        features = 9\n",
    "        joints = 14\n",
    "        # motion encoder\n",
    "        A = np.zeros((frame_batch, joints, features))\n",
    "        \n",
    "        for j in range(0,joints): # for each joint\n",
    "            for i in range(1,frame_batch):\n",
    "                # displacement \n",
    "      \n",
    "                A[i][j][0],  A[i][j][1]= batch[i][j] - batch[i-1][j]  \n",
    "                A[i][j][2] = math.sqrt(A[i][j][0]**2 + A[i][j][1]**2)\n",
    "\n",
    "                # speed\n",
    "                A[i][j][3],  A[i][j][4] = (batch[i][j] - batch[i-1][j])*fps \n",
    "                A[i][j][5] = A[i][j][2] * fps\n",
    "\n",
    "                # distance from joint j to spine_base\n",
    "                spine_base = (batch[i][8]+batch[i][11])/2\n",
    "                A[i][j][6], A[i][j][7] = batch[i][j] - spine_base\n",
    "                A[i][j][8] = math.sqrt(A[i][j][6]**2 + A[i][j][7]**2)\n",
    "\n",
    "        return A\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # encoded = []\n",
    "        # for kp in self.keypoints[index*frame_batch : (index+1)*frame_batch]:\n",
    "        #     encoded.append(self.encode(kp)) \n",
    "        # encoded = np.array(encoded)\n",
    "        # print(f\"Generated batch data shape: {encoded.shape}\")\n",
    "        return self.encode(self.keypoints[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d57e7cc-9990-4a68-a369-2faa867cbee9",
   "metadata": {
    "tags": [],
    "id": "6d57e7cc-9990-4a68-a369-2faa867cbee9",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "frame_batch = 128\n",
    "# Instantiate data Sequences for each split\n",
    "data_generator = Keypoints(frame_batch, keypoint_files[1:2])"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_generator[1].shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CK3Ryez7n8AM",
    "outputId": "99dc9119-b7fb-4f75-8922-6139a538ed6d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "CK3Ryez7n8AM",
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(128, 14, 9)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4ef8767c-31fa-447b-a7b4-4fc3ae708f6e",
   "metadata": {
    "tags": [],
    "id": "4ef8767c-31fa-447b-a7b4-4fc3ae708f6e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class DotLayer(tf.keras.layers.Layer):\n",
    " \n",
    "    def __init__(self, units=8):\n",
    "        super(DotLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # initialize the prototype\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True,\n",
    "                               name='dot_layer')\n",
    "        print(\"initialize the prototype\")\n",
    " \n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "050d46c6-33aa-4eb5-ac08-445af3a73b36",
   "metadata": {
    "tags": [],
    "id": "050d46c6-33aa-4eb5-ac08-445af3a73b36",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    # D: the dimension of the embedding features \n",
    "    # K: the number of cluster \n",
    "    # KL_weight: balance weight of the similarity term and the temporal order-preserving term\n",
    "    # SK_inter: the number of Sinkhorn-Knopp iteration\n",
    "    # alpha: weight of temporal coherence loss\n",
    "    def __init__(self, frame_batch, D=30, K=8, KL_weight=0.1, SK_inter=5, alpha=1.0, T=10.0):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.klw = KL_weight\n",
    "        self.nit = SK_inter\n",
    "\n",
    "        self.frame_batch = frame_batch\n",
    "        self.alpha = alpha\n",
    "        # self.model = self.build_model()\n",
    "\n",
    "        # 2-layer MLP   \n",
    "        self.dense1 = tf.keras.layers.Dense(units=2*D, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=D, activation='sigmoid')\n",
    "        self.dot1 = DotLayer()\n",
    "        self.softmax1 = tf.keras.layers.Softmax()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "      features = 9\n",
    "      joints = 14\n",
    "      D = self.D\n",
    "      T = self.T\n",
    "      frame_batch = self.frame_batch \n",
    "      x = inputs\n",
    "      x = tf.reshape(x, shape=(-1, joints*features))\n",
    "\n",
    "      x = self.dense1(x)\n",
    "      x = self.dense2(x)\n",
    "\n",
    "      self.Z = x\n",
    "\n",
    "      x = self.dot1(x)\n",
    "      outputs = self.softmax1(x/T)\n",
    "      \n",
    "      return outputs\n",
    "    \n",
    "    def compile(self):\n",
    "        super(MyModel, self).compile()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, weight_decay=1e-4)\n",
    "        \n",
    "    # build the encoder network\n",
    "    # def build_model(self):\n",
    "    #     features = 9\n",
    "    #     joints = 14\n",
    "    #     D = self.D\n",
    "    #     batch_size = self.batch_size\n",
    "    #     frame_batch = self.frame_batch \n",
    "    #     # inputs = keras.Input(shape=(joints, features))\n",
    "    #     inputs = keras.Input(shape=(frame_batch, joints, features))\n",
    "    #     x = inputs\n",
    "    #     # x = tf.keras.layers.Flatten()(x)\n",
    "    #     x = tf.reshape(x, shape=(-1, frame_batch, joints*features))\n",
    "        \n",
    "    #     # 2-layer MLP    \n",
    "    #     x = tf.keras.layers.Dense(units=2*D, activation='sigmoid')(x)\n",
    "    #     x = tf.keras.layers.Dense(units=D, activation='sigmoid')(x)\n",
    "        \n",
    "    #     # save the embedding features\n",
    "    #     self.Z = x\n",
    "\n",
    "    #     linear_layer = DotLayer()\n",
    "    #     x = linear_layer(x)\n",
    "    #     # P_ij \n",
    "    #     outputs = tf.keras.layers.Softmax()(x)\n",
    "        \n",
    "    #     return keras.Model(inputs, outputs)\n",
    "        \n",
    "    \n",
    "    def get_prior(self, x):\n",
    "        frame_batch = self.frame_batch\n",
    "        var = tf.math.reduce_variance(x)\n",
    "        std = tf.math.reduce_std(x)\n",
    "\n",
    "        T = []\n",
    "        for i in range(frame_batch):\n",
    "          T_i = []\n",
    "          for j in range(K):\n",
    "            d_ij = abs(i/frame_batch-j/K)/tf.math.sqrt(1/(frame_batch**2)+1/(K**2))\n",
    "            # Gaussian distribution \n",
    "            T_i.append(tf.math.exp(-d_ij**2/(2*var))/std*math.sqrt(2*math.pi))\n",
    "          T.append(T_i)\n",
    "        T = tf.stack(T)\n",
    "        return T\n",
    "        \n",
    "    def temporal_ot(self, x):\n",
    "        Z = self.Z\n",
    "        # C: learnable prototypes of the K clusters\n",
    "        C = self.trainable_variables[-1]\n",
    "        tf.print(tf.math.reduce_max(C))\n",
    "        T = self.get_prior(x)\n",
    "\n",
    "        \n",
    "        frame_batch = self.frame_batch\n",
    "        k_cluster = self.K\n",
    "        # balance weight of the similarity term and the temporal order-preserving term\n",
    "        klw = self.klw\n",
    "        \n",
    "        # Sinkhorn-Knopp Algorithm\n",
    "        v = np.ones((k_cluster,1))\n",
    "        u = np.ones((frame_batch,1))\n",
    "\n",
    "        a = u / frame_batch\n",
    "        b = v / k_cluster \n",
    "        K = tf.math.exp((tf.matmul(Z,C) + klw*tf.math.log(T))/klw) \n",
    "        # nit the number of Sinkhorn-Knopp iteration\n",
    "        for i in range(1,self.nit):\n",
    "        #v = b / np.dot(K.T, u), u = a / np.dot(K, v)\n",
    "          v = b / tf.matmul(tf.transpose(K), u)\n",
    "          u = a / tf.matmul(K, v)\n",
    "\n",
    "        v = tf.squeeze(v)\n",
    "        u = tf.squeeze(u)\n",
    "        \n",
    "        Q_TOT=tf.matmul(tf.linalg.diag(u),tf.matmul(K, tf.linalg.diag(v)))\n",
    "        tf.print(tf.math.reduce_max(Q_TOT))\n",
    "        return tf.stack(Q_TOT)\n",
    "        \n",
    "    def loss_func(self, P, Q):\n",
    "\n",
    "        frame_batch = self.frame_batch\n",
    "        # Cross-Entropy Loss\n",
    "        l_ce = -tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P)))/frame_batch\n",
    "        tf.print(tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P))))\n",
    "        # Temporal Coherence Loss - N pair loss\n",
    "        Z = self.Z\n",
    "        \n",
    "        N = 8\n",
    "        l = int(frame_batch/N)\n",
    "\n",
    "        Z_i = []\n",
    "        Z_positive = []\n",
    "        window_size = 4\n",
    "        # sample z_i\n",
    "        for i in range(N):\n",
    "          index = i*l + np.random.randint(0,l-1,1)\n",
    "          z_i = tf.gather(Z, index, axis=0)\n",
    "          Z_i.append(z_i)\n",
    "          \n",
    "          # calculate window range\n",
    "          min_index = max(0, index - window_size)\n",
    "          max_index = min(frame_batch - 1, index + window_size)\n",
    "          # sample z_postive inside the window\n",
    "          idx_pos = np.random.randint(min_index, max_index,1)\n",
    "          z_ip = tf.squeeze(tf.gather(Z, idx_pos, axis=0))\n",
    "          Z_positive.append(z_ip)\n",
    "\n",
    "        Z_i = tf.stack(Z_i)\n",
    "        Z_positive = tf.stack(Z_positive)\n",
    "\n",
    "\n",
    "        l_tc = 0\n",
    "        for i in range(N):  \n",
    "          denominator = tf.reduce_sum(tf.exp(tf.matmul(Z_i[i],tf.transpose(Z_positive))),axis=1, keepdims=True)\n",
    "          l_tc += tf.squeeze(tf.math.log(tf.exp(tf.matmul(Z_i[i],tf.reshape(Z_positive[i],shape=(self.D,1)))/denominator)))\n",
    "        l_tc = - l_tc/N\n",
    "        tf.print(\"LCE:\", l_ce,\"LTC:\",l_tc)\n",
    "        return 0.1*l_ce + self.alpha*l_tc\n",
    "        \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            P = self(x, training=True)\n",
    "            Q = self.temporal_ot(x)\n",
    "            loss = self.loss_func(P,Q)\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # update weights using the optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    def get_config(self):\n",
    "\n",
    "        return {\"frame_batch\": self.frame_batch,\"D\": self.D, \"K\": self.K,\"KL_weight\": self.klw,\"SK_inter\": self.nit,\"alpha\": self.alpha,\"T\": self.T}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb554543-9fc2-4c77-beb1-a2e097e51522",
   "metadata": {
    "tags": [],
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cb554543-9fc2-4c77-beb1-a2e097e51522",
    "outputId": "941f4215-90a5-4a34-d0fc-28dcdb7d5e84",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initialize the prototype\n",
      "Model: \"my_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_8 (Dense)             multiple                  7620      \n",
      "                                                                 \n",
      " dense_9 (Dense)             multiple                  1830      \n",
      "                                                                 \n",
      " dot_layer_4 (DotLayer)      multiple                  240       \n",
      "                                                                 \n",
      " softmax_4 (Softmax)         multiple                  0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,690\n",
      "Trainable params: 9,690\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = MyModel(128)\n",
    "model.compile()\n",
    "model.build(input_shape=(128, 14, 9))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "callbacks = [keras.callbacks.ModelCheckpoint(\"/content/gdrive/MyDrive/Colab Notebooks/logs/motion_tracking.h5\", save_best_only=True)]\n",
    "history = model.fit(data_generator, epochs=5, callbacks=callbacks)"
   ],
   "metadata": {
    "id": "-B_1H5tO683m",
    "outputId": "f55c67c5-44e6-437b-f0d4-f080a91d523d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "-B_1H5tO683m",
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/5\n",
      "0.156275511\n",
      "0.00237630308\n",
      "-2.07865405\n",
      "LCE: 0.0162394848 LTC: -0.0354671963\n",
      " 1/34 [..............................] - ETA: 3s - loss: -0.03380.156677559\n",
      "0.00266928226\n",
      "-2.07892585\n",
      "LCE: 0.0162416082 LTC: -0.0338396505\n",
      "0.15706861\n",
      "0.00225992873\n",
      "-2.07906866\n",
      "LCE: 0.0162427239 LTC: -0.0392670333\n",
      " 3/34 [=>............................] - ETA: 1s - loss: -0.03460.157445\n",
      "0.00218033418\n",
      "-2.07908297\n",
      "LCE: 0.0162428357 LTC: -0.0418485217\n",
      "0.157801747\n",
      "0.00195391942\n",
      "-2.07856035\n",
      "LCE: 0.0162387528 LTC: -0.0323261321\n",
      " 5/34 [===>..........................] - ETA: 1s - loss: -0.03490.158174008\n",
      "0.00253408402\n",
      "-2.07889986\n",
      "LCE: 0.0162414052 LTC: -0.0403650701\n",
      "0.158554882\n",
      "0.00240458082\n",
      "-2.07892561\n",
      "LCE: 0.0162416063 LTC: -0.044067096\n",
      " 7/34 [=====>........................] - ETA: 1s - loss: -0.03650.158919036\n",
      "0.00205158815\n",
      "-2.07867908\n",
      "LCE: 0.0162396803 LTC: -0.0440919213\n",
      "0.159274489\n",
      "0.00183787197\n",
      "-2.07911277\n",
      "LCE: 0.0162430685 LTC: -0.0427997336\n",
      " 9/34 [======>.......................] - ETA: 1s - loss: -0.03770.159614906\n",
      "0.00191812776\n",
      "-2.07888699\n",
      "LCE: 0.0162413046 LTC: -0.0436622389\n",
      "0.159946546\n",
      "0.00170675293\n",
      "-2.07934833\n",
      "LCE: 0.0162449088 LTC: -0.0453861728\n",
      "11/34 [========>.....................] - ETA: 1s - loss: -0.03870.160258457\n",
      "0.00185054541\n",
      "-2.07901669\n",
      "LCE: 0.0162423179 LTC: -0.045010753\n",
      "0.160552219\n",
      "0.00196833909\n",
      "-2.07884407\n",
      "LCE: 0.0162409693 LTC: -0.0438330807\n",
      "13/34 [==========>...................] - ETA: 0s - loss: -0.03930.160832137\n",
      "0.00191982836\n",
      "-2.07917166\n",
      "LCE: 0.0162435286 LTC: -0.0450394228\n",
      "0.161094695\n",
      "0.00217365753\n",
      "-2.07901478\n",
      "LCE: 0.016242303 LTC: -0.0449460819\n",
      "15/34 [============>.................] - ETA: 0s - loss: -0.03980.161343768\n",
      "0.0018355567\n",
      "-2.07907438\n",
      "LCE: 0.0162427686 LTC: -0.0442089252\n",
      "16/34 [=============>................] - ETA: 0s - loss: -0.04000.161578983\n",
      "0.00181431323\n",
      "-2.0791266\n",
      "LCE: 0.0162431765 LTC: -0.0438933633\n",
      "0.161804438\n",
      "0.00188025646\n",
      "-2.07894754\n",
      "LCE: 0.0162417777 LTC: -0.0435386971\n",
      "18/34 [==============>...............] - ETA: 0s - loss: -0.04020.162030295\n",
      "0.0025516469\n",
      "-2.07882833\n",
      "LCE: 0.0162408464 LTC: -0.0438079163\n",
      "0.162257805\n",
      "0.00196719076\n",
      "-2.0791924\n",
      "LCE: 0.0162436906 LTC: -0.0429233052\n",
      "20/34 [================>.............] - ETA: 0s - loss: -0.04040.162475467\n",
      "0.00182107091\n",
      "-2.07890868\n",
      "LCE: 0.0162414741 LTC: -0.0448864885\n",
      "0.162697\n",
      "0.00219249167\n",
      "-2.07916832\n",
      "LCE: 0.0162435025 LTC: -0.0432738215\n",
      "22/34 [==================>...........] - ETA: 0s - loss: -0.04060.162912965\n",
      "0.00198367238\n",
      "-2.07888198\n",
      "LCE: 0.0162412655 LTC: -0.0449889\n",
      "23/34 [===================>..........] - ETA: 0s - loss: -0.04070.163131312\n",
      "0.0020533409\n",
      "-2.07905364\n",
      "LCE: 0.0162426066 LTC: -0.0442949161\n",
      "0.163344756\n",
      "0.0019850051\n",
      "-2.07909846\n",
      "LCE: 0.0162429567 LTC: -0.0440521762\n",
      "25/34 [=====================>........] - ETA: 0s - loss: -0.04080.163549498\n",
      "0.00198742468\n",
      "-2.07871342\n",
      "LCE: 0.0162399486 LTC: -0.0451827906\n",
      "0.16377677\n",
      "0.00193075277\n",
      "-2.07904506\n",
      "LCE: 0.0162425395 LTC: -0.0445045568\n",
      "27/34 [======================>.......] - ETA: 0s - loss: -0.04100.164003268\n",
      "0.00227815658\n",
      "-2.07889056\n",
      "LCE: 0.0162413325 LTC: -0.045677416\n",
      "0.164242402\n",
      "0.00196726061\n",
      "-2.07899833\n",
      "LCE: 0.0162421744 LTC: -0.0439996533\n",
      "29/34 [========================>.....] - ETA: 0s - loss: -0.04120.164488897\n",
      "0.00183462398\n",
      "-2.07926416\n",
      "LCE: 0.0162442513 LTC: -0.0444756821\n",
      "0.16471763\n",
      "0.00269743428\n",
      "-2.07881975\n",
      "LCE: 0.0162407793 LTC: -0.0448738635\n",
      "31/34 [==========================>...] - ETA: 0s - loss: -0.04130.164972216\n",
      "0.00288100541\n",
      "-2.07900453\n",
      "LCE: 0.0162422229 LTC: -0.0451919\n",
      "0.165228203\n",
      "0.00202804338\n",
      "-2.07895827\n",
      "LCE: 0.0162418615 LTC: -0.0457374081\n",
      "33/34 [============================>.] - ETA: 0s - loss: -0.04150.165489838\n",
      "0.00191790052\n",
      "-2.07883787\n",
      "LCE: 0.0162409209 LTC: -0.0450748876\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/34 [==============================] - 2s 46ms/step - loss: -0.0416\n",
      "Epoch 2/5\n",
      "0.165767729\n",
      "0.00204282254\n",
      "-2.07868171\n",
      "LCE: 0.0162397 LTC: -0.0456505343\n",
      " 1/34 [..............................] - ETA: 3s - loss: -0.04400.166066781\n",
      "0.00274512917\n",
      "-2.07874846\n",
      "LCE: 0.0162402224 LTC: -0.0448660478\n",
      "0.166393951\n",
      "0.002062466\n",
      "-2.07886386\n",
      "LCE: 0.0162411239 LTC: -0.0452760123\n",
      " 3/34 [=>............................] - ETA: 1s - loss: -0.04360.166733071\n",
      "0.00175693631\n",
      "-2.07922435\n",
      "LCE: 0.0162439402 LTC: -0.0457549617\n",
      " 4/34 [==>...........................] - ETA: 1s - loss: -0.04380.167052791\n",
      "0.00236434862\n",
      "-2.07907414\n",
      "LCE: 0.0162427668 LTC: -0.0467350483\n",
      "0.167367026\n",
      "0.00203391165\n",
      "-2.07874346\n",
      "LCE: 0.0162401833 LTC: -0.0461990647\n",
      " 6/34 [====>.........................] - ETA: 1s - loss: -0.04410.167707026\n",
      "0.00257635955\n",
      "-2.07891774\n",
      "LCE: 0.0162415449 LTC: -0.0460336171\n",
      " 7/34 [=====>........................] - ETA: 1s - loss: -0.04420.168052405\n",
      "0.00200378522\n",
      "-2.07910585\n",
      "LCE: 0.0162430145 LTC: -0.0450046621\n",
      "0.168389231\n",
      "0.00209850445\n",
      "-2.07888627\n",
      "LCE: 0.016241299 LTC: -0.0464083403\n",
      " 9/34 [======>.......................] - ETA: 1s - loss: -0.04410.168738171\n",
      "0.00309416838\n",
      "-2.07885432\n",
      "LCE: 0.0162410494 LTC: -0.0458868183\n",
      "0.169087872\n",
      "0.00230197515\n",
      "-2.07860327\n",
      "LCE: 0.016239088 LTC: -0.0446886\n",
      "11/34 [========>.....................] - ETA: 1s - loss: -0.04410.169465333\n",
      "0.00188018661\n",
      "-2.07887292\n",
      "LCE: 0.0162411947 LTC: -0.04547856\n",
      "0.169856444\n",
      "0.00207119435\n",
      "-2.07892752\n",
      "LCE: 0.0162416212 LTC: -0.0457485653\n",
      "13/34 [==========>...................] - ETA: 1s - loss: -0.04400.170244515\n",
      "0.00213453546\n",
      "-2.07893372\n",
      "LCE: 0.0162416697 LTC: -0.0463172123\n",
      "0.170637548\n",
      "0.00203176029\n",
      "-2.07877111\n",
      "LCE: 0.0162404 LTC: -0.0453405976\n",
      "15/34 [============>.................] - ETA: 0s - loss: -0.04410.171048269\n",
      "0.00286907516\n",
      "-2.07860374\n",
      "LCE: 0.0162390918 LTC: -0.0465427637\n",
      "0.171486303\n",
      "0.00266034808\n",
      "-2.07861328\n",
      "LCE: 0.0162391663 LTC: -0.0465661585\n",
      "17/34 [==============>...............] - ETA: 0s - loss: -0.04420.171933845\n",
      "0.00226610899\n",
      "-2.07839632\n",
      "LCE: 0.0162374713 LTC: -0.0429603979\n",
      "0.172434792\n",
      "0.00255912915\n",
      "-2.07898211\n",
      "LCE: 0.0162420478 LTC: -0.046277035\n",
      "19/34 [===============>..............] - ETA: 0s - loss: -0.04400.172929421\n",
      "0.00265011098\n",
      "-2.07881212\n",
      "LCE: 0.0162407197 LTC: -0.0459110811\n",
      "0.173417017\n",
      "0.00235287845\n",
      "-2.0790925\n",
      "LCE: 0.0162429102 LTC: -0.0468510464\n",
      "21/34 [=================>............] - ETA: 0s - loss: -0.04410.173895\n",
      "0.00221269205\n",
      "-2.07880569\n",
      "LCE: 0.0162406694 LTC: -0.0462704264\n",
      "0.174375236\n",
      "0.00233040936\n",
      "-2.07908249\n",
      "LCE: 0.0162428319 LTC: -0.0465076715\n",
      "23/34 [===================>..........] - ETA: 0s - loss: -0.04420.17482771\n",
      "0.00228997506\n",
      "-2.07880664\n",
      "LCE: 0.0162406769 LTC: -0.0465534106\n",
      "0.175287083\n",
      "0.00233217236\n",
      "-2.07860804\n",
      "LCE: 0.0162391253 LTC: -0.0463811681\n",
      "25/34 [=====================>........] - ETA: 0s - loss: -0.04420.175766334\n",
      "0.00211098231\n",
      "-2.07873631\n",
      "LCE: 0.0162401274 LTC: -0.0455346853\n",
      "0.176262036\n",
      "0.00233947299\n",
      "-2.07915092\n",
      "LCE: 0.0162433665 LTC: -0.0456483662\n",
      "27/34 [======================>.......] - ETA: 0s - loss: -0.04420.176733822\n",
      "0.00225837529\n",
      "-2.0786767\n",
      "LCE: 0.0162396617 LTC: -0.0458902642\n",
      "0.177211866\n",
      "0.00255911425\n",
      "-2.07892203\n",
      "LCE: 0.0162415784 LTC: -0.04578669\n",
      "29/34 [========================>.....] - ETA: 0s - loss: -0.04420.177679047\n",
      "0.00249432959\n",
      "-2.07860708\n",
      "LCE: 0.0162391178 LTC: -0.046453692\n",
      "30/34 [=========================>....] - ETA: 0s - loss: -0.04420.178171813\n",
      "0.00214752555\n",
      "-2.07913637\n",
      "LCE: 0.0162432529 LTC: -0.0459629633\n",
      "0.178635851\n",
      "0.00234736875\n",
      "-2.07893157\n",
      "LCE: 0.0162416529 LTC: -0.0458731465\n",
      "32/34 [===========================>..] - ETA: 0s - loss: -0.04420.179098964\n",
      "0.00198221765\n",
      "-2.07905483\n",
      "LCE: 0.0162426159 LTC: -0.0449756645\n",
      "0.179556072\n",
      "0.00212043617\n",
      "-2.07841969\n",
      "LCE: 0.0162376538 LTC: -0.0453746021\n",
      "34/34 [==============================] - ETA: 0s - loss: -0.0442"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/34 [==============================] - 2s 46ms/step - loss: -0.0442\n",
      "Epoch 3/5\n",
      "0.180076748\n",
      "0.00243546255\n",
      "-2.07901049\n",
      "LCE: 0.0162422694 LTC: -0.0464869142\n",
      " 1/34 [..............................] - ETA: 3s - loss: -0.04490.180564761\n",
      "0.00217448547\n",
      "-2.07862139\n",
      "LCE: 0.0162392296 LTC: -0.0453473218\n",
      "0.181076229\n",
      "0.00246367604\n",
      "-2.07910347\n",
      "LCE: 0.0162429959 LTC: -0.0459521413\n",
      " 3/34 [=>............................] - ETA: 1s - loss: -0.04430.181562319\n",
      "0.00308042113\n",
      "-2.07857847\n",
      "LCE: 0.0162388943 LTC: -0.0454942\n",
      "0.182069167\n",
      "0.00258590933\n",
      "-2.07853079\n",
      "LCE: 0.0162385218 LTC: -0.046577476\n",
      " 5/34 [===>..........................] - ETA: 1s - loss: -0.04430.182599366\n",
      "0.00234673359\n",
      "-2.07875514\n",
      "LCE: 0.0162402745 LTC: -0.0460580736\n",
      "0.183130056\n",
      "0.00219658483\n",
      "-2.07848215\n",
      "LCE: 0.0162381418 LTC: -0.0470654555\n",
      " 7/34 [=====>........................] - ETA: 1s - loss: -0.04450.183685228\n",
      "0.00259697251\n",
      "-2.07871675\n",
      "LCE: 0.0162399746 LTC: -0.0468468927\n",
      "0.184243783\n",
      "0.00248174183\n",
      "-2.07860518\n",
      "LCE: 0.0162391029 LTC: -0.0470332727\n",
      " 9/34 [======>.......................] - ETA: 1s - loss: -0.04470.184806988\n",
      "0.00289287046\n",
      "-2.07897234\n",
      "LCE: 0.0162419714 LTC: -0.046909824\n",
      "0.185345888\n",
      "0.00232464541\n",
      "-2.07861042\n",
      "LCE: 0.0162391439 LTC: -0.0460805036\n",
      "11/34 [========>.....................] - ETA: 1s - loss: -0.04470.185898155\n",
      "0.00252148509\n",
      "-2.07839441\n",
      "LCE: 0.0162374564 LTC: -0.0467095859\n",
      "0.186469659\n",
      "0.00384100899\n",
      "-2.07866979\n",
      "LCE: 0.0162396077 LTC: -0.0459950864\n",
      "13/34 [==========>...................] - ETA: 0s - loss: -0.04470.187036708\n",
      "0.00284598768\n",
      "-2.0786891\n",
      "LCE: 0.0162397586 LTC: -0.0461486503\n",
      "0.187600896\n",
      "0.00265389588\n",
      "-2.07858038\n",
      "LCE: 0.0162389092 LTC: -0.0456890613\n",
      "15/34 [============>.................] - ETA: 0s - loss: -0.04470.188164562\n",
      "0.0024858769\n",
      "-2.07865405\n",
      "LCE: 0.0162394848 LTC: -0.0463791564\n",
      "0.188720271\n",
      "0.00293057039\n",
      "-2.07876015\n",
      "LCE: 0.0162403136 LTC: -0.0457088\n",
      "17/34 [==============>...............] - ETA: 0s - loss: -0.04460.189253628\n",
      "0.00234372914\n",
      "-2.07891297\n",
      "LCE: 0.0162415076 LTC: -0.0449483953\n",
      "0.189768478\n",
      "0.00270495564\n",
      "-2.07894468\n",
      "LCE: 0.0162417553 LTC: -0.0460831337\n",
      "19/34 [===============>..............] - ETA: 0s - loss: -0.04460.190255\n",
      "0.00218425319\n",
      "-2.07847571\n",
      "LCE: 0.0162380915 LTC: -0.0459047891\n",
      "0.190773442\n",
      "0.00240347255\n",
      "-2.07830119\n",
      "LCE: 0.0162367281 LTC: -0.0462653972\n",
      "21/34 [=================>............] - ETA: 0s - loss: -0.04460.191323638\n",
      "0.00237643905\n",
      "-2.07841206\n",
      "LCE: 0.0162375942 LTC: -0.0463660769\n",
      "0.191885874\n",
      "0.00202952418\n",
      "-2.07925272\n",
      "LCE: 0.0162441619 LTC: -0.0456702784\n",
      "23/34 [===================>..........] - ETA: 0s - loss: -0.04450.192421332\n",
      "0.00304505229\n",
      "-2.07863879\n",
      "LCE: 0.0162393656 LTC: -0.0466589481\n",
      "0.192956269\n",
      "0.00232682377\n",
      "-2.07805324\n",
      "LCE: 0.0162347909 LTC: -0.0453338139\n",
      "25/34 [=====================>........] - ETA: 0s - loss: -0.04450.193568066\n",
      "0.00303912815\n",
      "-2.07877278\n",
      "LCE: 0.0162404124 LTC: -0.0467511937\n",
      "0.19416599\n",
      "0.00279644504\n",
      "-2.07866049\n",
      "LCE: 0.0162395351 LTC: -0.0471622646\n",
      "27/34 [======================>.......] - ETA: 0s - loss: -0.04460.194748074\n",
      "0.00251105428\n",
      "-2.07864189\n",
      "LCE: 0.0162393898 LTC: -0.0461605\n",
      "0.195328236\n",
      "0.00296406448\n",
      "-2.0785439\n",
      "LCE: 0.0162386242 LTC: -0.0461861715\n",
      "29/34 [========================>.....] - ETA: 0s - loss: -0.04460.195904061\n",
      "0.00290144235\n",
      "-2.07840395\n",
      "LCE: 0.0162375309 LTC: -0.0469581559\n",
      "0.196511313\n",
      "0.00367244706\n",
      "-2.0779798\n",
      "LCE: 0.0162342172 LTC: -0.0470603555\n",
      "31/34 [==========================>...] - ETA: 0s - loss: -0.04460.197144181\n",
      "0.00287963077\n",
      "-2.0779407\n",
      "LCE: 0.0162339117 LTC: -0.0442527682\n",
      "32/34 [===========================>..] - ETA: 0s - loss: -0.04460.197847277\n",
      "0.00276065804\n",
      "-2.07900763\n",
      "LCE: 0.0162422471 LTC: -0.0456479564\n",
      "0.19852075\n",
      "0.0035407953\n",
      "-2.07821965\n",
      "LCE: 0.016236091 LTC: -0.0474269949\n",
      "34/34 [==============================] - ETA: 0s - loss: -0.0446"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/34 [==============================] - 2s 44ms/step - loss: -0.0446\n",
      "Epoch 4/5\n",
      "0.199195608\n",
      "0.00293753203\n",
      "-2.0784893\n",
      "LCE: 0.0162381977 LTC: -0.0470863953\n",
      " 1/34 [..............................] - ETA: 3s - loss: -0.04550.19984968\n",
      "0.0030111447\n",
      "-2.07797241\n",
      "LCE: 0.0162341595 LTC: -0.0445762612\n",
      "0.200563252\n",
      "0.00326854\n",
      "-2.07819343\n",
      "LCE: 0.0162358861 LTC: -0.0471753553\n",
      " 3/34 [=>............................] - ETA: 1s - loss: -0.04470.201280072\n",
      "0.00255066901\n",
      "-2.07845259\n",
      "LCE: 0.0162379108 LTC: -0.046358645\n",
      "0.201978788\n",
      "0.00277759507\n",
      "-2.07826757\n",
      "LCE: 0.0162364654 LTC: -0.0466054976\n",
      " 5/34 [===>..........................] - ETA: 1s - loss: -0.04470.202689171\n",
      "0.00260561891\n",
      "-2.0777545\n",
      "LCE: 0.016232457 LTC: -0.0455728\n",
      "0.203456402\n",
      "0.00310795475\n",
      "-2.07832742\n",
      "LCE: 0.0162369329 LTC: -0.045465976\n",
      " 7/34 [=====>........................] - ETA: 1s - loss: -0.04450.204223916\n",
      "0.00322548766\n",
      "-2.07818\n",
      "LCE: 0.0162357818 LTC: -0.0457950681\n",
      "0.204974085\n",
      "0.00311621092\n",
      "-2.07827473\n",
      "LCE: 0.0162365213 LTC: -0.0468740389\n",
      " 9/34 [======>.......................] - ETA: 1s - loss: -0.04450.205716863\n",
      "0.00281246\n",
      "-2.07831383\n",
      "LCE: 0.0162368268 LTC: -0.0465050712\n",
      "0.206450626\n",
      "0.0034825094\n",
      "-2.07857537\n",
      "LCE: 0.0162388701 LTC: -0.046862673\n",
      "11/34 [========>.....................] - ETA: 1s - loss: -0.04460.207169831\n",
      "0.00224063918\n",
      "-2.07808781\n",
      "LCE: 0.016235061 LTC: -0.0460571796\n",
      "0.207914278\n",
      "0.00385801867\n",
      "-2.07835269\n",
      "LCE: 0.0162371304 LTC: -0.0459249765\n",
      "13/34 [==========>...................] - ETA: 0s - loss: -0.04460.208621413\n",
      "0.00268392265\n",
      "-2.07890558\n",
      "LCE: 0.0162414499 LTC: -0.0457422435\n",
      "0.209303737\n",
      "0.00321193039\n",
      "-2.07771063\n",
      "LCE: 0.0162321143 LTC: -0.047419291\n",
      "15/34 [============>.................] - ETA: 0s - loss: -0.04460.21000725\n",
      "0.00360046327\n",
      "-2.07773709\n",
      "LCE: 0.016232321 LTC: -0.0469062664\n",
      "0.210741684\n",
      "0.00292721204\n",
      "-2.07900405\n",
      "LCE: 0.0162422191 LTC: -0.0458035655\n",
      "17/34 [==============>...............] - ETA: 0s - loss: -0.04470.211416796\n",
      "0.00346236303\n",
      "-2.07848024\n",
      "LCE: 0.0162381269 LTC: -0.0474465713\n",
      "0.212061718\n",
      "0.00320468284\n",
      "-2.07784986\n",
      "LCE: 0.0162332021 LTC: -0.0465422161\n",
      "19/34 [===============>..............] - ETA: 0s - loss: -0.04470.212752953\n",
      "0.00346368179\n",
      "-2.07783437\n",
      "LCE: 0.016233081 LTC: -0.0475013703\n",
      "0.213448927\n",
      "0.00396325439\n",
      "-2.07842255\n",
      "LCE: 0.0162376761 LTC: -0.0473136455\n",
      "21/34 [=================>............] - ETA: 0s - loss: -0.04480.214113519\n",
      "0.00299320091\n",
      "-2.0779171\n",
      "LCE: 0.0162337273 LTC: -0.0461431146\n",
      "0.214824617\n",
      "0.00380951911\n",
      "-2.07816434\n",
      "LCE: 0.0162356589 LTC: -0.0467177592\n",
      "23/34 [===================>..........] - ETA: 0s - loss: -0.04480.215505689\n",
      "0.00341702253\n",
      "-2.07835603\n",
      "LCE: 0.0162371565 LTC: -0.0447546169\n",
      "0.216158122\n",
      "0.00522491336\n",
      "-2.07779741\n",
      "LCE: 0.0162327923 LTC: -0.0461214073\n",
      "25/34 [=====================>........] - ETA: 0s - loss: -0.04470.216805726\n",
      "0.00413642079\n",
      "-2.07742858\n",
      "LCE: 0.0162299108 LTC: -0.0478893854\n",
      "0.217467025\n",
      "0.0044184532\n",
      "-2.07707047\n",
      "LCE: 0.0162271131 LTC: -0.0473396629\n",
      "27/34 [======================>.......] - ETA: 0s - loss: -0.04480.218158767\n",
      "0.00320972968\n",
      "-2.07722378\n",
      "LCE: 0.0162283108 LTC: -0.046948988\n",
      "0.218885124\n",
      "0.00349339098\n",
      "-2.07775378\n",
      "LCE: 0.0162324514 LTC: -0.0472184718\n",
      "29/34 [========================>.....] - ETA: 0s - loss: -0.04490.219627067\n",
      "0.00365779549\n",
      "-2.07856727\n",
      "LCE: 0.0162388068 LTC: -0.0464136824\n",
      "0.220308289\n",
      "0.00424515456\n",
      "-2.0786097\n",
      "LCE: 0.0162391383 LTC: -0.0463450104\n",
      "31/34 [==========================>...] - ETA: 0s - loss: -0.04490.220955759\n",
      "0.00453814119\n",
      "-2.07865906\n",
      "LCE: 0.0162395239 LTC: -0.0459668674\n",
      "32/34 [===========================>..] - ETA: 0s - loss: -0.04490.221554905\n",
      "0.00331285223\n",
      "-2.07711267\n",
      "LCE: 0.0162274428 LTC: -0.0470644757\n",
      "0.222183153\n",
      "0.00375513732\n",
      "-2.07790732\n",
      "LCE: 0.016233651 LTC: -0.0466315262\n",
      "34/34 [==============================] - ETA: 0s - loss: -0.0449"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/34 [==============================] - 2s 43ms/step - loss: -0.0449\n",
      "Epoch 5/5\n",
      "0.222814858\n",
      "0.00332871079\n",
      "-2.07769966\n",
      "LCE: 0.0162320286 LTC: -0.0466939323\n",
      " 1/34 [..............................] - ETA: 3s - loss: -0.04510.223447263\n",
      "0.00393682346\n",
      "-2.07754564\n",
      "LCE: 0.0162308253 LTC: -0.0456594378\n",
      "0.224097967\n",
      "0.00442752242\n",
      "-2.0784452\n",
      "LCE: 0.0162378531 LTC: -0.0463657603\n",
      " 3/34 [=>............................] - ETA: 1s - loss: -0.04460.224709108\n",
      "0.00470053405\n",
      "-2.07695222\n",
      "LCE: 0.0162261892 LTC: -0.0481670164\n",
      "0.225338876\n",
      "0.00360199437\n",
      "-2.0774796\n",
      "LCE: 0.0162303094 LTC: -0.0468126312\n",
      " 5/34 [===>..........................] - ETA: 1s - loss: -0.04510.226019308\n",
      "0.00458143279\n",
      "-2.07757473\n",
      "LCE: 0.0162310526 LTC: -0.0472580232\n",
      "0.226685628\n",
      "0.00484180078\n",
      "-2.07845211\n",
      "LCE: 0.0162379071 LTC: -0.0459601469\n",
      " 7/34 [=====>........................] - ETA: 1s - loss: -0.04510.227300361\n",
      "0.00459862873\n",
      "-2.07794642\n",
      "LCE: 0.0162339564 LTC: -0.0474546514\n",
      "0.227897838\n",
      "0.00343033671\n",
      "-2.07764459\n",
      "LCE: 0.0162315983 LTC: -0.0459027477\n",
      " 9/34 [======>.......................] - ETA: 1s - loss: -0.04510.22848855\n",
      "0.00399149\n",
      "-2.07806754\n",
      "LCE: 0.0162349027 LTC: -0.0453471653\n",
      "0.229057968\n",
      "0.00522844493\n",
      "-2.07784748\n",
      "LCE: 0.0162331834 LTC: -0.0473745391\n",
      "11/34 [========>.....................] - ETA: 0s - loss: -0.04500.229635015\n",
      "0.00429599546\n",
      "-2.0776372\n",
      "LCE: 0.0162315406 LTC: -0.0478476733\n",
      "0.230192319\n",
      "0.00428675115\n",
      "-2.07736683\n",
      "LCE: 0.0162294284 LTC: -0.0474510305\n",
      "13/34 [==========>...................] - ETA: 0s - loss: -0.04520.230755746\n",
      "0.00413424149\n",
      "-2.07645273\n",
      "LCE: 0.016222287 LTC: -0.0454251729\n",
      "0.231407464\n",
      "0.00457159057\n",
      "-2.07687593\n",
      "LCE: 0.0162255932 LTC: -0.0474997535\n",
      "15/34 [============>.................] - ETA: 0s - loss: -0.04510.232053459\n",
      "0.00355660915\n",
      "-2.07703376\n",
      "LCE: 0.0162268262 LTC: -0.0468551889\n",
      "0.232718661\n",
      "0.00409272313\n",
      "-2.07639122\n",
      "LCE: 0.0162218064 LTC: -0.0471727178\n",
      "17/34 [==============>...............] - ETA: 0s - loss: -0.04520.233408734\n",
      "0.00496116467\n",
      "-2.07605791\n",
      "LCE: 0.0162192024 LTC: -0.0474964157\n",
      "0.234130979\n",
      "0.00567875803\n",
      "-2.07662487\n",
      "LCE: 0.0162236318 LTC: -0.0463188402\n",
      "19/34 [===============>..............] - ETA: 0s - loss: -0.04520.234851211\n",
      "0.00399271026\n",
      "-2.07636094\n",
      "LCE: 0.0162215699 LTC: -0.0469868965\n",
      "0.235583141\n",
      "0.00396448933\n",
      "-2.07635474\n",
      "LCE: 0.0162215214 LTC: -0.0481869\n",
      "21/34 [=================>............] - ETA: 0s - loss: -0.04520.236345246\n",
      "0.00496649742\n",
      "-2.07724214\n",
      "LCE: 0.0162284542 LTC: -0.0467191376\n",
      "0.237083271\n",
      "0.00341238827\n",
      "-2.07810545\n",
      "LCE: 0.0162351988 LTC: -0.045977179\n",
      "23/34 [===================>..........] - ETA: 0s - loss: -0.04520.237814113\n",
      "0.00364648364\n",
      "-2.07597\n",
      "LCE: 0.0162185151 LTC: -0.0472882763\n",
      "0.238586754\n",
      "0.00320235267\n",
      "-2.07578087\n",
      "LCE: 0.016217038 LTC: -0.0456011221\n",
      "25/34 [=====================>........] - ETA: 0s - loss: -0.04520.239444971\n",
      "0.00280253962\n",
      "-2.07690454\n",
      "LCE: 0.0162258167 LTC: -0.0465468504\n",
      "0.240339801\n",
      "0.00446952134\n",
      "-2.07700634\n",
      "LCE: 0.016226612 LTC: -0.0467830934\n",
      "27/34 [======================>.......] - ETA: 0s - loss: -0.04520.241217032\n",
      "0.00496934354\n",
      "-2.07764196\n",
      "LCE: 0.0162315778 LTC: -0.0468048193\n",
      "0.242037967\n",
      "0.00442792475\n",
      "-2.07657099\n",
      "LCE: 0.0162232108 LTC: -0.0479335114\n",
      "29/34 [========================>.....] - ETA: 0s - loss: -0.04520.242873564\n",
      "0.00571301579\n",
      "-2.07689166\n",
      "LCE: 0.0162257161 LTC: -0.0460422747\n",
      "0.243665546\n",
      "0.0047396142\n",
      "-2.07641554\n",
      "LCE: 0.0162219964 LTC: -0.0456360355\n",
      "31/34 [==========================>...] - ETA: 0s - loss: -0.04510.244455785\n",
      "0.00495924614\n",
      "-2.07850647\n",
      "LCE: 0.0162383318 LTC: -0.0457918309\n",
      "0.245192781\n",
      "0.00541812927\n",
      "-2.07561827\n",
      "LCE: 0.0162157677 LTC: -0.0479288064\n",
      "33/34 [============================>.] - ETA: 0s - loss: -0.04510.245950669\n",
      "0.00444322079\n",
      "-2.07627439\n",
      "LCE: 0.0162208937 LTC: -0.0460376665\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r34/34 [==============================] - 2s 44ms/step - loss: -0.0451\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1,6)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "4d2TRuvvlTrH",
    "outputId": "3a14f8ef-cbd8-4ebc-b03e-af8be668c4af",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "4d2TRuvvlTrH",
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# save model\n",
    "model.save('/content/gdrive/MyDrive/Colab Notebooks/logs/my_model')"
   ],
   "metadata": {
    "id": "eGJ6lBh4gq5z",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "eGJ6lBh4gq5z",
   "execution_count": 59,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "P = model.predict(data_generator[0])"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRXgpjOFVJsf",
    "outputId": "34a4f70f-1c94-4a67-88a0-bbe7ef2d8320",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "aRXgpjOFVJsf",
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4/4 [==============================] - 0s 2ms/step\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "P = np.argmax(P, axis=1)"
   ],
   "metadata": {
    "id": "MSSYVGgHd3yJ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "MSSYVGgHd3yJ",
   "execution_count": 61,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "np.mean(P)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPn4xsB2fgab",
    "outputId": "46ab21b7-9129-43f4-a1ac-9696b753a513",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "RPn4xsB2fgab",
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4.578125"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "P"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sTAngD-9fiTX",
    "outputId": "7dffad7b-64c3-4a3c-8ae1-8c42e23c12d7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "sTAngD-9fiTX",
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 0, 7, 2, 2, 4, 7, 2, 7, 7, 7, 7, 7, 7, 7, 7, 4, 7, 7, 7, 2, 2,\n",
       "       4, 7, 2, 7, 7, 7, 7, 4, 7, 7, 7, 2, 7, 2, 7, 7, 4, 4, 7, 7, 7, 2,\n",
       "       7, 7, 7, 7, 7, 4, 2, 2, 7, 7, 7, 2, 4, 7, 2, 7, 2, 7, 7, 7, 7, 7,\n",
       "       7, 2, 7, 7, 7, 2, 7, 7, 7, 7, 2, 7, 7, 2, 4, 2, 7, 4, 4, 7, 0, 4,\n",
       "       4, 0, 4, 0, 4, 4, 0, 2, 4, 4, 0, 4, 4, 7, 4, 4, 4, 4, 4, 4, 7, 4,\n",
       "       2, 7, 2, 2, 6, 7, 0, 2, 2, 0, 4, 0, 4, 2, 2, 4, 0, 0])"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "MNPlTgJN52sR",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "MNPlTgJN52sR",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "colab": {
   "provenance": []
  },
  "gpuClass": "premium",
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}