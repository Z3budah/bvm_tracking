{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814e3cb-5dda-4ed2-98f7-2d7ef59743f1",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ab81a6-7ff0-443d-bac2-5a83b5318d48",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filePath = '../lab/LSTM_training.mat'\n",
    "data = loadmat(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9688f-4166-4133-a019-cab6ae3d4d3e",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['DLC_sequences'][2219][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046017d3-e4fb-48a7-93b7-19f0bfc7e44a",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['DLC_sequences'][:2219].shape # left leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f86545a-3d66-49d6-a9fc-a8db04b682e0",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data['DLC_sequences'][2219:].shape # right leg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "left_leg_90 = [\n",
    "    data['DLC_sequences'][:2219][i][0]\n",
    "    for i in range(0,2219)\n",
    "    if data['DLC_sequences'][:2219][i][0].shape[1]==90\n",
    "]\n",
    "left_leg_75 = [\n",
    "    data['DLC_sequences'][:2219][i][0]\n",
    "    for i in range(0,2219)\n",
    "    if data['DLC_sequences'][:2219][i][0].shape[1]==75\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "left_leg_90 = np.array(left_leg_90)\n",
    "left_leg_75 = np.array(left_leg_75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 75)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_leg_75[1].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [],
   "source": [
    "# sequence class to load and vectorize batches of data\n",
    "class Keypoints(keras.utils.Sequence):\n",
    "    def __init__(self, keypoint_array):\n",
    "        self.keypoints = keypoint_array\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.keypoints)\n",
    "\n",
    "    def encode(self, batch):\n",
    "        frame_batch = self.keypoints.shape[2]\n",
    "        fps = frame_batch / 3.0\n",
    "        features = 12\n",
    "        joints = self.keypoints.shape[1] // 2\n",
    "\n",
    "        # motion encoder\n",
    "        A = np.zeros((frame_batch, joints, features))\n",
    "\n",
    "        for j in range(0,joints): # for each joint\n",
    "            for i in range(1,frame_batch):\n",
    "                # displacement\n",
    "                A[i][j][0] = batch[2*j][i]- batch[2*j][i-1]\n",
    "                A[i][j][1] = batch[2*j + 1][i]- batch[2*j+1][i-1]\n",
    "                A[i][j][2] = math.sqrt(A[i][j][0]**2 + A[i][j][1]**2)\n",
    "\n",
    "                # speed\n",
    "                A[i][j][3] = A[i][j][0]*fps\n",
    "                A[i][j][4] = A[i][j][1]*fps\n",
    "                A[i][j][5] = A[i][j][2]*fps\n",
    "\n",
    "                # acceleration\n",
    "                A[i][j][6] = (A[i][j][3]-A[i-1][j][3])*fps\n",
    "                A[i][j][7] = (A[i][j][4]-A[i-1][j][4])*fps\n",
    "                A[i][j][8] = (A[i][j][5]-A[i-1][j][5])*fps\n",
    "\n",
    "\n",
    "                # distance from joint j to spine_base(hip_cd)\n",
    "                A[i][j][9] = batch[2*j][i]- batch[0][i]\n",
    "                A[i][j][10] = batch[2*j + 1][i]- batch[1][i]\n",
    "                A[i][j][11] = math.sqrt(A[i][j][9]**2 + A[i][j][10]**2)\n",
    "\n",
    "        return A\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # encoded = []\n",
    "        # for kp in self.keypoints[index*frame_batch : (index+1)*frame_batch]:\n",
    "        #     encoded.append(self.encode(kp))\n",
    "        # encoded = np.array(encoded)\n",
    "        # print(f\"Generated batch data shape: {encoded.shape}\")\n",
    "        return self.encode(self.keypoints[index])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "# Instantiate data Sequences for each split\n",
    "data_generator = Keypoints(left_leg_75)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75, 3, 12)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class DotLayer(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, units=8):\n",
    "        super(DotLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # initialize the prototype\n",
    "        self.w = self.add_weight(shape=(input_shape[-1], self.units),\n",
    "                               initializer='random_normal',\n",
    "                               trainable=True,\n",
    "                               name='dot_layer')\n",
    "        print(\"initialize the prototype\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        return tf.matmul(inputs, self.w)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"units\": self.units}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fae0943-eb1f-4397-87a3-bce42cd86b08",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    # D: the dimension of the embedding features \n",
    "    # K: the number of cluster \n",
    "    # KL_weight: balance weight of the similarity term and the temporal order-preserving term\n",
    "    # SK_inter: the number of Sinkhorn-Knopp iteration\n",
    "    # alpha: weight of temporal coherence loss\n",
    "    def __init__(self,frame_batch,features,joints, D=30, K=8, KL_weight=0.1, SK_inter=5, alpha=1.0, T=10.0):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.klw = KL_weight\n",
    "        self.nit = SK_inter\n",
    "        \n",
    "        self.frame_batch = frame_batch\n",
    "        \n",
    "        self.features = features\n",
    "        self.joints = joints\n",
    "\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # 2-layer MLP   \n",
    "        self.dense1 = tf.keras.layers.Dense(units=2*D, activation='sigmoid')\n",
    "        self.dense2 = tf.keras.layers.Dense(units=D, activation='sigmoid')\n",
    "        self.dot1 = DotLayer()\n",
    "        self.softmax1 = tf.keras.layers.Softmax()\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "\n",
    "        features = self.features \n",
    "        joints = self.joints\n",
    "        D = self.D\n",
    "        T = self.T\n",
    "        frame_batch = self.frame_batch\n",
    "        x = inputs\n",
    "        x = tf.reshape(x, shape=(-1, joints*features))\n",
    "\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "\n",
    "        self.Z = x\n",
    "\n",
    "        x = self.dot1(x)\n",
    "        outputs = self.softmax1(x/T)\n",
    "        return outputs\n",
    "    \n",
    "    def compile(self):\n",
    "        super(MyModel, self).compile()\n",
    "        self.optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, decay=1e-4)\n",
    "        \n",
    "    def get_prior(self, x):\n",
    "        frame_batch = self.frame_batch\n",
    "        var = tf.math.reduce_variance(x)\n",
    "        std = tf.math.reduce_std(x)\n",
    "\n",
    "        T = []\n",
    "        K = self.K\n",
    "        for i in range(frame_batch):\n",
    "            T_i = []\n",
    "            for j in range(K):\n",
    "                d_ij = abs(i/frame_batch-j/K)/tf.math.sqrt(1/(frame_batch**2)+1/(K**2))\n",
    "                # Gaussian distribution \n",
    "                T_i.append(tf.math.exp(-d_ij**2/(2*var))/std*math.sqrt(2*math.pi))\n",
    "            T.append(T_i)\n",
    "        T = tf.stack(T)\n",
    "        return T\n",
    "        \n",
    "    def temporal_ot(self, x):\n",
    "        Z = self.Z\n",
    "        # C: learnable prototypes of the K clusters\n",
    "        C = self.trainable_variables[-1]\n",
    "        tf.print(tf.math.reduce_max(C))\n",
    "        T = self.get_prior(x)\n",
    "\n",
    "        \n",
    "        frame_batch = self.frame_batch\n",
    "        k_cluster = self.K\n",
    "        # balance weight of the similarity term and the temporal order-preserving term\n",
    "        klw = self.klw\n",
    "        \n",
    "        # Sinkhorn-Knopp Algorithm\n",
    "        v = np.ones((k_cluster,1))\n",
    "        u = np.ones((frame_batch,1))\n",
    "\n",
    "        a = u / frame_batch\n",
    "        b = v / k_cluster \n",
    "        K = tf.math.exp((tf.matmul(Z,C) + klw*tf.math.log(T))/klw) \n",
    "        # nit the number of Sinkhorn-Knopp iteration\n",
    "        for i in range(1,self.nit):\n",
    "            #v = b / np.dot(K.T, u), u = a / np.dot(K, v)\n",
    "            v = b / tf.matmul(tf.transpose(K), u)\n",
    "            u = a / tf.matmul(K, v)\n",
    "\n",
    "        v = tf.squeeze(v)\n",
    "        u = tf.squeeze(u)\n",
    "        \n",
    "        Q_TOT=tf.matmul(tf.linalg.diag(u),tf.matmul(K, tf.linalg.diag(v)))\n",
    "        tf.print(tf.math.reduce_max(Q_TOT))\n",
    "        return tf.stack(Q_TOT)\n",
    "        \n",
    "    def loss_func(self, P, Q):\n",
    "\n",
    "        frame_batch = self.frame_batch\n",
    "        # Cross-Entropy Loss\n",
    "        l_ce = -tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P)))/frame_batch\n",
    "        tf.print(tf.math.reduce_sum(tf.multiply(Q,tf.math.log(P))))\n",
    "        # Temporal Coherence Loss - N pair loss\n",
    "        Z = self.Z\n",
    "        \n",
    "        N = 8\n",
    "        l = int(frame_batch/N)\n",
    "\n",
    "        Z_i = []\n",
    "        Z_positive = []\n",
    "        window_size = 4\n",
    "        # sample z_i\n",
    "        for i in range(N):\n",
    "            index = i*l + np.random.randint(0,l-1,1)\n",
    "            z_i = tf.gather(Z, index, axis=0)\n",
    "            Z_i.append(z_i)\n",
    "            \n",
    "            # calculate window range\n",
    "            min_index = max(0, index - window_size)\n",
    "            max_index = min(frame_batch - 1, index + window_size)\n",
    "            # sample z_postive inside the window\n",
    "            idx_pos = np.random.randint(min_index, max_index,1)\n",
    "            z_ip = tf.squeeze(tf.gather(Z, idx_pos, axis=0))\n",
    "            Z_positive.append(z_ip)\n",
    "\n",
    "        Z_i = tf.stack(Z_i)\n",
    "        Z_positive = tf.stack(Z_positive)\n",
    "\n",
    "\n",
    "        l_tc = 0\n",
    "        for i in range(N):  \n",
    "            denominator = tf.reduce_sum(tf.exp(tf.matmul(Z_i[i],tf.transpose(Z_positive))),axis=1, keepdims=True)\n",
    "            l_tc += tf.squeeze(tf.math.log(tf.exp(tf.matmul(Z_i[i],tf.reshape(Z_positive[i],shape=(self.D,1)))/denominator)))\n",
    "        l_tc = - l_tc/N\n",
    "        tf.print(\"LCE:\", l_ce,\"LTC:\",l_tc)\n",
    "        return l_ce + self.alpha*l_tc\n",
    "        \n",
    "        \n",
    "    def train_step(self, data):\n",
    "        x = data\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            P = self(x, training=True)\n",
    "            Q = self.temporal_ot(x)\n",
    "            loss = self.loss_func(P,Q)\n",
    "        # compute gradients\n",
    "        gradients = tape.gradient(loss, self.trainable_variables)\n",
    "        # update weights using the optimizer\n",
    "        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\n",
    "        \n",
    "        return {'loss': loss}\n",
    "    def get_config(self):\n",
    "\n",
    "        return {\"frame_batch\": self.frame_batch,\"D\": self.D, \"K\": self.K,\"KL_weight\": self.klw,\"SK_inter\": self.nit,\"alpha\": self.alpha,\"T\": self.T}\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52410f3-145a-4f5c-8b4d-4bdb913cff86",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = MyModel(data_generator[0].shape[0],3,12)\n",
    "model.compile()\n",
    "callbacks = [keras.callbacks.ModelCheckpoint(\"motion_tracking.h5\", save_best_only=True)]\n",
    "model.build(input_shape=(None, 3, 12))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7111a7f-1a22-4370-8b32-6e4a60c508ad",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_generator[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8c8f1e-1f27-49b3-bf1a-16be8f89afa9",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit(data_generator, epochs=5, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dc7ab5-d505-4d57-9fad-59224035eed4",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "\n",
    "epochs = range(1,6)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01632689-6bb5-4dfa-a58a-17c89f999895",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def draw_segment(P):\n",
    "    # Generate a random array with numbers from 0 to 7\n",
    "    # data_array = np.random.randint(0, 8, size=75)\n",
    "    data_array = P\n",
    "    print(data_array.shape)\n",
    "    # Create a color map for the segments\n",
    "    colors = ['red', 'green', 'blue', 'orange', 'yellow', 'purple', 'brown', 'pink']\n",
    "    cmap = ListedColormap(colors)\n",
    "\n",
    "    segment_indices = np.arange(75)\n",
    "\n",
    "    # Calculate the lengths of each segment\n",
    "    segment_lengths = np.ones(75)\n",
    "\n",
    "    # Plot the segmented bar chart\n",
    "    fig, ax = plt.subplots(figsize=(12, 2))\n",
    "\n",
    "    plt.bar(segment_indices, segment_lengths, color=cmap(data_array[segment_indices]), width=1)\n",
    "\n",
    "    # Customize the chart\n",
    "    plt.xlabel('Frame')\n",
    "    plt.ylabel('Segment')\n",
    "    plt.title('Segmented Bar Chart')\n",
    "\n",
    "    plt.subplots_adjust(left=0, right=1, bottom=0, top=1)\n",
    "    # Display the chart\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d79f7be-028a-407e-a90e-8889a2a08fc6",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "P = model.predict(data_generator[0])\n",
    "P = np.argmax(P, axis=1)\n",
    "P.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df435d8a-a65e-47bc-b0f6-2ae1dbf39588",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "draw_segment(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdd0263-f38d-49e2-98b9-4e664c2247c2",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x = range(0,243)\n",
    "y = [\n",
    "    np.argmax(model.predict(data), axis=1).mean()\n",
    "    for data in data_generator\n",
    "]\n",
    "y = np.array(y)\n",
    "\n",
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017df83-c196-4c95-bfed-81e50cfc4374",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "import logging"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "gma_json=os.path.join(\"../action/gma/baseline.json\")\n",
    "gma_video =os.path.join( \"../action/gma/baseline.mp4\")\n",
    "gma_segment = \"../action/gma\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(gma_json, \"r\") as f:\n",
    "                data = json.load(f)\n",
    "except Exception as e:\n",
    "    logging.error(\"Failed to load annotation file:{}\".format(e))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "video_id = list(data.keys())[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(gma_video)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492 360 25.0\n"
     ]
    }
   ],
   "source": [
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(width, height, fps)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "for idx, annotation in enumerate(data.get(video_id, [])):\n",
    "    start_frame = annotation[\"segment\"][0]\n",
    "    end_frame = annotation[\"segment\"][1]\n",
    "    label = annotation.get(\"label\", None)\n",
    "    duration_frame = annotation.get(\"duration_frame\", None)\n",
    "\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, start_frame)\n",
    "\n",
    "    output_file = str(idx) + \".mp4\" if label is None else label + \"_\" + str(idx) + \".mp4\"\n",
    "    output_path = gma_segment + '/' + output_file\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    output_video = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "\n",
    "    for frame_idx in range(start_frame, end_frame + 1):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        output_video.write(frame)\n",
    "\n",
    "    output_video.release()\n",
    "cap.release()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1,3,4,5]\n",
    "b = 4\n",
    "b in a"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}